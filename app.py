import streamlit as st
from openai import OpenAI  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ –Ω–æ–≤–æ–≥–æ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è
import docx
import requests
from config import OPENROUTER_API_KEY, HUGGINGFACE_TOKEN

# -------------------- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è --------------------
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã Streamlit
st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–æ–Ω–∞ –∑–≤–æ–Ω–∫–æ–≤",
    page_icon="üìû",
    layout="wide"
)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üìû –ê–≥–µ–Ω—Ç –æ—Ü–µ–Ω–∫–∏ —Ç–æ–Ω–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤")
st.markdown("""
–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—É—é —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (—Ç–µ–∫—Å—Ç –∏–ª–∏ —Ñ–∞–π–ª), –∏ –ò–ò –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –µ–≥–æ –æ–±—â–∏–π —Ç–æ–Ω –∏ –¥–∞—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é.
*–†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ OpenRouter –∏ –º–æ–¥–µ–ª–∏ DeepSeek V3.*
""")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenRouter :cite[2]
client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=OPENROUTER_API_KEY,
)

# URL –¥–ª—è Hugging Face API
API_URL = "https://router.huggingface.co/hf-inference/models/distilbert/distilbert-base-uncased-finetuned-sst-2-english"
headers = {
    "Authorization": f"Bearer {HUGGINGFACE_TOKEN}",
}


# -------------------- –§—É–Ω–∫—Ü–∏–∏ --------------------
def query(payload):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Hugging Face API"""
    response = requests.post(API_URL, headers=headers, json=payload)
    return response.json()


def extract_text_from_file(uploaded_file):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""
    try:
        if uploaded_file.type == "text/plain":
            return str(uploaded_file.read(), "utf-8")
        elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            doc = docx.Document(uploaded_file)
            return "\n".join([paragraph.text for paragraph in doc.paragraphs])
        else:
            st.error("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ .txt –∏ .docx —Ñ–∞–π–ª—ã.")
            return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return None


def analyze_sentiment_with_api(text):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é Hugging Face API."""
    if not HUGGINGFACE_TOKEN:
        return {"error": "–¢–æ–∫–µ–Ω Hugging Face –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."}

    try:
        output = query({"inputs": text[:512]})

        if isinstance(output, list) and len(output) > 0:
            most_confident = max(output[0], key=lambda x: x['score'])
            return most_confident
        elif isinstance(output, dict) and 'error' in output:
            return {"error": output['error']}
        else:
            return {"error": "–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API"}

    except requests.exceptions.RequestException as e:
        return {"error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Hugging Face API: {e}"}
    except Exception as e:
        return {"error": f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {e}"}


def generate_llm_recommendations(text, sentiment_label):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ OpenRouter API –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ –∏ —Ç–æ–Ω–∞."""
    if not OPENROUTER_API_KEY:
        return "–û—à–∏–±–∫–∞: API –∫–ª—é—á OpenRouter –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."

    try:
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        prompt = f"""
        –¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –±–∏–∑–Ω–µ—Å-—Ç—Ä–µ–Ω–µ—Ä –ø–æ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è–º. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É —Ç–µ–ª–µ—Ñ–æ–Ω–Ω–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.

        –¢–û–ù –†–ê–ó–ì–û–í–û–†–ê: {sentiment_label}
        –¢–ï–ö–°–¢ –†–ê–ó–ì–û–í–û–†–ê: 
        \"\"\"{text}\"\"\"

        –î–∞–π 1-2 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∫–∞–∫ —É–ª—É—á—à–∏—Ç—å –ø–æ–¥–æ–±–Ω—ã–µ —Ä–∞–∑–≥–æ–≤–æ—Ä—ã –≤ –±—É–¥—É—â–µ–º.
        –û—Ç–≤–µ—Ç –≤—ã–¥–∞–π –≤ –≤–∏–¥–µ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞, –±–µ–∑ –ª–∏—à–Ω–∏—Ö –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π.
        """

        # –í—ã–∑–æ–≤ OpenRouter API
        completion = client.chat.completions.create(
            model="deepseek/deepseek-chat-v3-0324:free",
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=150,
            temperature=0.7
        )
        return completion.choices[0].message.content.strip()

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}"

# -------------------- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å --------------------
with st.sidebar:
    st.header("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è")
    if OPENROUTER_API_KEY:
        st.success("API –∫–ª—é—á OpenRouter –∑–∞–≥—Ä—É–∂–µ–Ω")
    else:
        st.error("API –∫–ª—é—á OpenRouter –Ω–µ –Ω–∞–π–¥–µ–Ω")

    if HUGGINGFACE_TOKEN:
        st.success("–¢–æ–∫–µ–Ω Hugging Face –∑–∞–≥—Ä—É–∂–µ–Ω")
    else:
        st.warning("–¢–æ–∫–µ–Ω Hugging Face –Ω–µ –Ω–∞–π–¥–µ–Ω")

    st.markdown("""
    **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤:**
    - –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã (.txt)
    - –î–æ–∫—É–º–µ–Ω—Ç—ã Word (.docx)

    **–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Å–µ—Ä–≤–∏—Å—ã:**
    - –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: Hugging Face Inference API
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: DeepSeek V3 —á–µ—Ä–µ–∑ OpenRouter :cite[1]
    """)

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
input_method = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –≤–≤–æ–¥–∞:", ["–¢–µ–∫—Å—Ç", "–§–∞–π–ª"])

input_text = ""

if input_method == "–¢–µ–∫—Å—Ç":
    input_text = st.text_area("–í–≤–µ–¥–∏—Ç–µ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É —Ç–µ–ª–µ—Ñ–æ–Ω–Ω–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:", height=250,
                              placeholder="–°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏ —Å—é–¥–∞...")
else:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π", type=["txt", "docx"])
    if uploaded_file is not None:
        input_text = extract_text_from_file(uploaded_file)
        if input_text:
            st.text_area("–¢–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞:", value=input_text, height=250)

if st.button("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", type="primary"):
    if not input_text.strip():
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        st.stop()

    # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—â–∏–π —Ç–æ–Ω —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ —á–µ—Ä–µ–∑ Hugging Face API..."):
        sentiment_result = analyze_sentiment_with_api(input_text)

    if "error" in sentiment_result:
        st.error(sentiment_result["error"])
        st.stop()

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    sentiment_label = sentiment_result['label']
    sentiment_score = sentiment_result['score']

    sentiment_labels_ru = {
        "POSITIVE": "–ü–û–ó–ò–¢–ò–í–ù–´–ô",
        "NEGATIVE": "–ù–ï–ì–ê–¢–ò–í–ù–´–ô",
        "NEUTRAL": "–ù–ï–ô–¢–†–ê–õ–¨–ù–´–ô",
        "LABEL_0": "–ù–ï–ì–ê–¢–ò–í–ù–´–ô",
        "LABEL_1": "–ù–ï–ô–¢–†–ê–õ–¨–ù–´–ô",
        "LABEL_2": "–ü–û–ó–ò–¢–ò–í–ù–´–ô"
    }

    sentiment_label_ru = sentiment_labels_ru.get(sentiment_label, sentiment_label)

    st.success("–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    col1, col2 = st.columns(2)
    with col1:
        st.metric(label="**–ü—Ä–µ–æ–±–ª–∞–¥–∞—é—â–∏–π —Ç–æ–Ω**", value=sentiment_label_ru)
    with col2:
        st.metric(label="**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏**", value=f"{sentiment_score:.2f}")

    # –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —á–µ—Ä–µ–∑ LLM
    with st.spinner("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é –ò–ò..."):
        recommendations = generate_llm_recommendations(input_text, sentiment_label_ru)

    st.subheader("üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:")
    st.markdown(recommendations)

# -------------------- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –±–ª–æ–∫ --------------------
with st.expander("‚ÑπÔ∏è –û –¥–∞–Ω–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏"):
    st.markdown("""
    –≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ **–ò–ò-–∞–≥–µ–Ω—Ç–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–≤–æ–Ω–∫–æ–≤**, —Å–æ–∑–¥–∞–Ω–Ω–æ–µ –≤ —Ä–∞–º–∫–∞—Ö —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è.

    **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
    - **–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:** –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ Hugging Face Inference API.
    - **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:** –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ DeepSeek V3 —á–µ—Ä–µ–∑ OpenRouter :cite[1].
    - **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–∞–π–ª–æ–≤:** –†–∞–±–æ—Ç–∞ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏ (.txt) –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ Word (.docx).
    - **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:** –ö–ª—é—á–∏ API —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ, –∏—Å–∫–ª—é—á–µ–Ω–Ω–æ–º –∏–∑ —Å–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è –≤–µ—Ä—Å–∏–π.

    **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:** Python, Streamlit, Hugging Face Inference API, OpenRouter API, python-docx
    """)

with st.expander("‚ö†Ô∏è –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫"):
    st.markdown("""
    **–ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
    1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ —Ñ–∞–π–ª–µ `.env` —É–∫–∞–∑–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω Hugging Face
    2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –Ω–∞ –≤–∞—à–µ–º –∞–∫–∫–∞—É–Ω—Ç–µ Hugging Face –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ Inference API

    **–ï—Å–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
    1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å OpenRouter API –∫–ª—é—á–∞ –≤ —Ñ–∞–π–ª–µ `.env`
    2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –Ω–∞ –≤–∞—à–µ–º –∞–∫–∫–∞—É–Ω—Ç–µ OpenRouter –µ—Å—Ç—å –∫—Ä–µ–¥–∏—Ç—ã :cite[10]
    3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –º–æ–¥–µ–ª—å `deepseek/deepseek-chat-v3-0324:free` –¥–æ—Å—Ç—É–ø–Ω–∞ :cite[1]

    **–ö–æ–¥—ã –æ—à–∏–±–æ–∫ OpenRouter:** :cite[3]
    - 400: –ù–µ–≤–µ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    - 401: –ù–µ–≤–µ—Ä–Ω—ã–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    - 402: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤
    - 403: –ú–æ–¥–µ—Ä–∞—Ü–∏—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∞
    - 408: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞
    - 429: –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤
    - 502: –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏
    - 503: –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
    """)